<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: CONTRIBUTING</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">CONTRIBUTING</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Please see the wiki for more information.</p>
<p>B B --&gt; C C --&gt; D D --&gt; E E --&gt; F F --&gt; G G --&gt; H H --&gt; I G --&gt; J</p>
<p>K --&gt; L L --&gt; M M --&gt; D </p>
<h3><a class="anchor" id="autotoc_md2"></a>
Build Requirements</h3>
<p>To build this library from source, you will need:</p><ul>
<li>Python 3.10+</li>
<li>GCC or Clang that supports at least C++20</li>
<li>A 64-bit Unix-like system</li>
<li>(Optional) libomp/OpenMP</li>
</ul>
<p>Note: In theory, Windows can compile the entire project with no issues. However, since MSVC is a completely different beast to GCC or Clang, no build options have been added to support it. MinGW would also probably work.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md4"></a>
Nomenclature</h2>
<h3><a class="anchor" id="autotoc_md5"></a>
Z2R</h3>
<p><em>Also know as 'Voids', 'bit_string'.</em> <br  />
Is defined as: $\mathbb{Z}_2$ Rows.</p>
<ul>
<li>'$\mathbb{Z}_2$' denotes the cyclic group of integers modulo 2 (i.e the set {0, 1}).</li>
<li>'Rows' states that the structure is a row (list) of elements.</li>
</ul>
<p>Thus, the structure is a long list of binary 1s and 0s. This packed representation significantly reduces memory usage and enables efficient bitwise operations.</p><ul>
<li>Python: <code>z = np.array([0, 1, 1 0], dtype=np.int8)</code>. This takes 4 bytes of memory</li>
<li>C++: <code>z = 0b0110</code>. This takes 1 byte of memory</li>
</ul>
<h3><a class="anchor" id="autotoc_md6"></a>
CZ2M</h3>
<p>Is defined as: C $\mathbb{Z}_2$ Matrix</p>
<p>This name is in reference to the C++ module which operates on Z2Rs to produce matrices.</p>
<h3><a class="anchor" id="autotoc_md7"></a>
The bitwise_[...] prefix</h3>
<p>Any functions with this prefix must be declared inside of <code>bitops.hpp</code> and adhere to the following:</p><ol type="1">
<li>Must accept any size and shape of NDArrays, as long as every input is the same shape and contiguous.</li>
<li>Must return an NDArray of the same shape, size, and dtype as the inputs.</li>
<li>Follows as closely as possible NumPy's functions of the same name.</li>
</ol>
<p>The only execeptions to rule 2 are <code><a class="el" href="bitops_8h.html#a0ef1198a1ae9103694e3faae1ff654b4" title="Counts the number of set bits in each element of a NumPy contiguous (C-like) array....">bitwise_count()</a></code> and <code><a class="el" href="bitops_8h.html#af09e23aeabfe87eebbafdf5550643992" title="Computes the bitwise dot product between corresponding elements of two NumPy contiguous (C-like) arra...">bitwise_dot()</a></code>, which both compress the last dimension of the array.</p>
<hr  />
<h3><a class="anchor" id="autotoc_md9"></a>
General Coding Standards</h3>
<p><b>Avoid Broadcasting in C++:</b> Broadcasting is a complex process that required substantial engineering effort from the NumPy team to implement efficiently. Rather than reimplementing ourself broadcasting in C++, either:</p><ul>
<li>Perform broadcasting in Python before passing data to C++</li>
<li>Use pybind11's <a href="https://pybind11.readthedocs.io/en/stable/advanced/pycpp/numpy.html#vectorizing-functions">vectorize</a> functionality when dealing with simple functions</li>
</ul>
<p><b>Avoid Uncontiguous Data</b>: The speedup made by this library is mainly due to the contiguity of NDArrays, and how this property can be exploited with extreme compiler optimizations (SIMD) or by careful implementation of certain patterns and structure. For uncontiguous data, either: TODO: EXPLAIN CONTIGUITY IN DETAIL!</p><ul>
<li>Rearange the data in Python before passing it to C++</li>
<li>Explicitly state that slowdowns may occur (idk).</li>
</ul>
<p><b>Memory Management:</b> C++ lacks garbage collection or Rust's borrow checker, so you must manually manage memory efficiently:</p><ul>
<li>Track pointer lifetimes carefully to avoid dangling pointers</li>
<li>Prefer zero-copy operations whenever possible</li>
<li>Only allocate new memory when necessary</li>
</ul>
<p><b>Type Specifications:</b></p><ul>
<li>Use <code>py::array_t&lt;TYPE&gt;</code> for typed arrays (e.g., <code>py::array_t&lt;float&gt;</code> for NDArrays of floats)</li>
<li>Use generic <code>py::array</code> for Voids (packed binary data)</li>
</ul>
<p><b>Binary Data Types:</b> Since C++ has no native 'binary' type, a substitute one must be chosen instead. Use these types because they guarantee exact bit lengths and support both arithmetic and binary operations:</p><ul>
<li><code>uint64_t</code>: 64-bit unsigned integer (for large data inputs)</li>
<li><code>uint8_t</code>: 8-bit unsigned integer (for small data)</li>
<li><code>int64_t</code>: 64-bit signed integer. Use ONLY for returning outputs</li>
</ul>
<p>Avoid:</p><ul>
<li><code>std::byte</code> (no arithmetic support) TODO: Clarify size garantees</li>
<li><code>unsigned char</code> (no size guarantee)</li>
<li><code>unsigned long long int</code> (unnecessarily verbose)</li>
</ul>
<p><b>Do not use <code>using namespace std;</code></b> While convenient, namespace imports create ambiguity in low-level code. Both the standard library and pybind11 may define functions with identical names (e.g., <code>make_tuple()</code>), which would result in unpredicable function calls. Explicit namespace prefixes ensure:</p><ul>
<li>Functions are called from the correct library</li>
<li>Code behavior is predictable</li>
<li>Future maintainers understand the code's intent</li>
</ul>
<h3><a class="anchor" id="autotoc_md10"></a>
Docstrings</h3>
<p>A Python docstring such as: </p><div class="fragment"><div class="line"> python</div>
<div class="line"> </div>
<div class="line">def add_integers(a:int, b:int) -&gt; int:</div>
<div class="line">    &quot;&quot;&quot;</div>
<div class="line">    Calculates the sum of two integers</div>
<div class="line">    Args:</div>
<div class="line">        a (int): The first operand</div>
<div class="line">        b (int): The second operand</div>
<div class="line">    Returns:</div>
<div class="line">        int: The sum of both inputs</div>
<div class="line">    &quot;&quot;&quot;</div>
<div class="line">    return a + b</div>
</div><!-- fragment --><p>Is roughly equivalent to the Doxygen comment: </p><div class="fragment"><div class="line"> c++</div>
<div class="line">/**</div>
<div class="line">* @brief Calculates the sum of two integers</div>
<div class="line">*</div>
<div class="line">* @param a The first integer operand</div>
<div class="line">* @param b The second integer operand</div>
<div class="line">* @return int The sum of both inputs</div>
<div class="line">*/</div>
<div class="line">int add_integers(int a, int b) {</div>
<div class="line">    return a + b;</div>
<div class="line">}</div>
</div><!-- fragment --><p> Additional Doxygen tags include <code>@deprecated</code>, <code>@attention</code>, and <code>@warning</code>, which are used throughout the project where appropriate.</p>
<h3><a class="anchor" id="autotoc_md11"></a>
Auto-formatter</h3>
<p>Since Black is only usable for Python files, we instead use <a href="https://clang.llvm.org/docs/ClangFormat.html">clang-format</a>, a highly customizable formatter that we can adjust to look more or less like Black.</p>
<p>All of the options are found inside of the <code>.clang-format</code> file. As a base, we use LLVM's coding format and override some specific options:</p><ul>
<li><code>UseTab: Never</code>: Always forces spaces for indentation</li>
<li><code>IndentWidth: 4</code>: Use 4-space standard for indentation</li>
<li><code>IndentPPDirectives: AfterHash</code>: Indent preprocessor directives after their '#'</li>
</ul>
<h1><a class="anchor" id="autotoc_md12"></a>
Interacting with Python</h1>
<p>We use <a href="https://github.com/pybind/pybind11">pybind11</a> to interface between Python and C++. Pybind11 was chosen over alternatives like Boost.Python for its:</p><ul>
<li>Seamless NumPy NDArray integration</li>
<li>Superior performance</li>
<li>Modern C++ support</li>
</ul>
<p>Include these headers at the top of files that interact with Python: </p><div class="fragment"><div class="line"> C++</div>
<div class="line">#include &lt;pybind11/pybind11.h&gt;</div>
<div class="line">#include &lt;pybind11/numpy.h&gt;</div>
<div class="line">namespace py = pybind11;</div>
</div><!-- fragment --><p> Note: Omit <code>&lt;pybind11/numpy.h&gt;</code> if you don't need to pass NumPy arrays.</p>
<h3><a class="anchor" id="autotoc_md13"></a>
Writing Functions</h3>
<p>C++ requires a lot more work and boilerplate in order to get the same result as in Python. The following functions both flip every bit of data inside of an NDArray:</p>
<p>Python: <a href="https://numpy.org/doc/stable/reference/generated/numpy.bitwise_invert.html#numpy.bitwise_invert">https://numpy.org/doc/stable/reference/generated/numpy.bitwise_invert.html#numpy.bitwise_invert</a> </p><div class="fragment"><div class="line"> python</div>
<div class="line">def bitwise_not(voids: NDArray) -&gt; NDArray:</div>
<div class="line">    int_strings = voids_to_int_strings(voids)</div>
<div class="line">    new_int_strings = np.invert(int_strings)</div>
<div class="line">    new_voids = int_strings_to_voids(new_int_strings)</div>
<div class="line"> </div>
<div class="line">    return new_voids</div>
</div><!-- fragment --><p>C++: </p><div class="fragment"><div class="line"> C++</div>
<div class="line">inline py::array bitwise_not(py::array voids) {</div>
<div class="line">    auto buffer = voids.request();</div>
<div class="line">    const uint64_t *ptr_64 = std::bit_cast&lt;uint64_t *&gt;(buffer.ptr);</div>
<div class="line">    py::array result_arr = py::array(voids.dtype(), buffer.shape);</div>
<div class="line">    // ...</div>
<div class="line">    uint64_t *result_ptr_64 = std::bit_cast&lt;uint64_t *&gt;(result_arr.request().ptr);</div>
<div class="line">    // ...</div>
<div class="line">    for (int i = 0; i &lt; TOTAL_NUM_64_CHUNKS; i++) {</div>
<div class="line">        result_ptr_64[i] = ~ptr_64[i];</div>
<div class="line">    }</div>
<div class="line">    return result_arr</div>
<div class="line">}</div>
</div><!-- fragment --><p> Lets look at the function declaration:</p><ul>
<li><code>inline</code> means that the following function will be <em>expanded</em> instead of <em>called</em> from any other functions. What this means in practice is that the external call will be entirely replaced with the actual code of this function. This increases binary file sizes but reduces traditional function call overhead.</li>
<li><code>py::array</code> declares an object that is a generic NDArray with no specific type.</li>
</ul>
<p>And as for the code within the function:</p><ul>
<li><code>auto buffer = voids.request()</code>: Creates a buffer object with type inferred at compile time. The <code>request()</code> method returns a zero-copy view of the NDArray's data when possible.</li>
<li><code>std::bit_cast&lt;uint64_t *&gt;</code> is a near zero-overhead reinterpretation of the data underneath.</li>
<li><code>py::array result_arr = py::array(voids.dtype(), buffer.shape)</code>: Creates a new NDArray with the same dtype and shape as the input. This array can be returned directly to Python.</li>
<li><code>ptr_out_64[i] = ~ptr_64[i]</code> inverts the chunk of 64 bits and assigns the result to our result pointer</li>
</ul>
<h3><a class="anchor" id="autotoc_md14"></a>
Exposing Functions to Python (Bindings)</h3>
<p>All C++ functions must be declared in their module's binding file to be accessible from Python. Lets say we want to add <code>bitwise_not</code> to our module, </p><div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="preprocessor">#include &quot;your_source_file.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_function" href="bitops__bindings_8cpp.html#a12fc346c4c701932d86ea75773e67423">PYBIND11_MODULE</a>(your_module_name, m) {</div>
<div class="line">    m.doc() = <span class="stringliteral">&quot;The description of your module&quot;</span>;</div>
<div class="line">    </div>
<div class="line">    m.def(<span class="stringliteral">&quot;bitwise_not&quot;</span>, &amp;<a class="code hl_function" href="bitops_8h.html#aedb22dda43c8c1563273c77ac707c0c2">bitwise_not</a>, </div>
<div class="line">          <span class="stringliteral">&quot;Flips each bit in an NDArray&quot;</span>, </div>
<div class="line">          py::arg(<span class="stringliteral">&quot;voids&quot;</span>));</div>
<div class="line">}</div>
<div class="ttc" id="abitops_8h_html_aedb22dda43c8c1563273c77ac707c0c2"><div class="ttname"><a href="bitops_8h.html#aedb22dda43c8c1563273c77ac707c0c2">bitwise_not</a></div><div class="ttdeci">py::array bitwise_not(py::array voids)</div><div class="ttdoc">Performs an element-wise bitwise NOT operation on a NumPy contiguous (C-like) array....</div><div class="ttdef"><b>Definition</b> bitops.cpp:74</div></div>
<div class="ttc" id="abitops__bindings_8cpp_html_a12fc346c4c701932d86ea75773e67423"><div class="ttname"><a href="bitops__bindings_8cpp.html#a12fc346c4c701932d86ea75773e67423">PYBIND11_MODULE</a></div><div class="ttdeci">PYBIND11_MODULE(_bitops, m)</div><div class="ttdef"><b>Definition</b> bitops_bindings.cpp:7</div></div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md15"></a>
Optimization Efforts</h1>
<h2><a class="anchor" id="autotoc_md16"></a>
General</h2>
<p>In most cases, we cast the data of a Voids array to <code>uint64_t</code> via <code>std::bit_cast&lt;&gt;</code>. This is done because in most modern computers, 64 bits is the largest natively supported integer size. Even when an arrayâ€™s dimension is smaller than 64 bits, treating it as a sequence of raw 64-bit blocks enables highly optimized bitwise manipulation and reduces overhead.</p>
<h2><a class="anchor" id="autotoc_md17"></a>
Multi-threading</h2>
<p>To fully utilize available hardware, we implement multi-threading wherever safe and beneficial. OpenMP provides simple syntax with powerful results while maintaining code readability. </p>
<h3><a class="anchor" id="autotoc_md18"></a>
Using OpenMP</h3>
<p>Before adding OpenMP, make it <b>certain</b> that your code is thread-safe. Data races and memory corruption are difficult to debug. While mutexes can provide thread safety over otherwise unsafe operations, they often cause performance degradation in small functions (our primary use case). Use mutexes cautiously and verify they provide net benefits.</p>
<p>As for the syntax, most <em>for(...)</em> loops in the project are prefaced with: </p><div class="fragment"><div class="line"> C++</div>
<div class="line">#ifdef USE_OPENMP</div>
<div class="line">    #pragma omp parallel for if (local_variable &gt;= SOME_MACRO) schedule(static)</div>
<div class="line">#endif</div>
<div class="line">    for (i=0; i&lt;local_variable; i++) {</div>
<div class="line">        // Code that does something which could be multi-threaded</div>
<div class="line">    }</div>
</div><!-- fragment --><ul>
<li><code>#ifdef</code> is a preprocessor directive that only compiles it's code block if the specific macro is defined. In this case, <code>USE_OPENMP</code> is our own macro, and is only ever defined within CMake's compiling instruction. This is necessary since if OpenMP is not installed but still tries to compile OMP-specific pragmas, the compiler will throw out an error and exit.</li>
<li><code>#pragma omp parallel for</code> says that we'll be using OpenMP's directives, which will pass the next <em>for(...)</em> loop to multiple threads.</li>
<li><code>if (local_variable &gt;= SOME_MACRO)</code> assures that the multithreading only occurs if the statement evaluates to True. Usually this is with a counter or size of a data point compared to an arbitrarily chosen constant.</li>
<li><code>schedule(static)</code> assign each loop iterations to threads in a even, round-robin distribution.</li>
</ul>
<p>More keywords exist, but they are specific to certain behaviors that are much less common in this project</p>
<h3><a class="anchor" id="autotoc_md19"></a>
Understanding the GIL</h3>
<p>Python's Global Interpreter Lock allows only one thread to execute Python bytecode at a time. This simplifies Python's memory management but prevents true multi-threading. Only multiprocessing can achieve true parallelism under the GIL.</p>
<p>However, it is possible to get freed from the shackles of the GIL within C++. This can be done by declaring a section like this: </p><div class="fragment"><div class="line"> ++</div>
<div class="line">{</div>
<div class="line">  py::gil_scoped_release release;</div>
<div class="line">  <span class="comment">// very heavy CPU loop (Real multithreading allowed)</span></div>
<div class="line">}</div>
<div class="line"><span class="comment">// The GIL is automaticaly reaquired here</span></div>
</div><!-- fragment --><p> Releasing the GIL has some overhead, so it is only useful when code needs to be truly parallelized. <b>Release the GIL when:</b></p><ul>
<li>Operations are CPU-intensive and long-running</li>
<li>No Python API calls are needed</li>
<li>Using OpenMP or manual threading</li>
</ul>
<p>See <code><a class="el" href="cz2m_8h.html#ae4da4fa68c447ad16c8312e9e6938628" title="This is a very early test implementation of unordered unique. It finds unique rows in a NumPy 2D arra...">unordered_unique()</a></code>'s management of the GIL and OpenMP for more information. It is the very last function inside of <code>paulicpp/pauliarray/src/paulicpp.hpp</code></p>
<p>Note: The Python language is working towards removing the GIL. This could take many years before it is accomplished, buf if/when it finished, there will likely be some breakage around any parts explicitly managing the GIL. See <a href="https://peps.python.org/pep-0703/">PEP 703</a></p>
<h2><a class="anchor" id="autotoc_md20"></a>
Building</h2>
<p>WIP </p>
<h3><a class="anchor" id="autotoc_md21"></a>
pyproject.toml</h3>
<p><code>scikit-build-core</code> is the build backend as Flit not currently compatible with custom C++ compilation steps.</p>
<p>sasssaaa</p>
<h3><a class="anchor" id="autotoc_md22"></a>
CMake</h3>
<p>CMake is a cross-platform build tool. It has clean integration with pybind11 and <code>scikit-build-core</code> for <code>pip install</code> support.</p>
<p>The configuration file is <code>CMakeLists.txt</code>, found in the project root.</p>
<p><b>Build Options:</b></p><ul>
<li><code>USE_OPENMP</code>: Enable/disable OpenMP multi-threading<ul>
<li>Default: <code>ON</code></li>
<li>Disable manually in <code>CMakeLists.txt</code> or via pip: <code>pip install . --config-settings=cmake.define.USE_OPENMP=OFF</code></li>
</ul>
</li>
</ul>
<hr  />
<h1><a class="anchor" id="autotoc_md24"></a>
Name</h1>
<h2><a class="anchor" id="autotoc_md25"></a>
Why C++?</h2>
<ol type="1">
<li>Performance: Most operations can be sped-up with either precise bit-on-bit algorithms and/or extreme compiler optimizations (like SIMD). Results are usually between 1.5-9x faster than pure NumPy<ol type="a">
<li>Memory: Handling Pauli strings within C++ allows for packed representations with next to no compromises. Less RAM </li>
</ol>
</li>
</ol>
<h2><a class="anchor" id="autotoc_md26"></a>
3. Flexibility: C++ offers total control over what a function needs to do. This is especially useful when XYZ</h2>
<h1><a class="anchor" id="autotoc_md27"></a>
External tools and libraries</h1>
<p>The tools used for this project are:</p><ul>
<li>pybind11</li>
<li>pybind-stubgen</li>
<li>CMake</li>
<li>clang-format</li>
</ul>
<h2><a class="anchor" id="autotoc_md28"></a>
Why pybind11?</h2>
<p>Pybind11 was chosen for its minimal boilerplate, seamless NumPy integration, and modern C++ support. It allows us to expose C++ functions and classes to Python with very little overhead, making it easy to maintain and extend the codebase.</p>
<p>Since pybind is chosen as the interface for this project, the stub generator is obviously pybind-stubgen. However, some problems have appeared with it, notably when trying to add external libraries. It may get replaced with mypy's stubgen in the future.</p>
<p>Other alternatives for optimizing code to work with Python are:</p>
<ol type="1">
<li><b>Numba</b><ul>
<li>While Numba is excellent for accelerating generic Python code, our data structures are highly specialized and already optimized in C++. Numba would offer limited additional benefit and cannot easily accelerate C++ code.</li>
</ul>
</li>
<li><b>Cython</b><ul>
<li>Cython is powerful for optimizing Python code and interfacing with C, but it often requires rewriting parts (if not most) of functions to take full advantage of its features. At that point, we might as well rewrite everything in pure C/C++</li>
</ul>
</li>
<li><b>Boost.Python</b><ul>
<li>Boost.Python is feature-rich but introduces significant overhead and complexity. It requires more boilerplate code, demands loads more dependencies, and is generally slower compared to pybind11.</li>
</ul>
</li>
</ol>
<h1><a class="anchor" id="autotoc_md29"></a>
Data structures</h1>
<p>Handling long lists of 1s and 0s is at the heart of this project, and needs to be done as efficiently as possible. The current way all data is managed is throught a packed representation of integers.</p>
<p>Example: <code>ex = 0b01100111</code> stored in a unsigned integer. <br  />
</p><ul>
<li>Drawback: for extreme cases where almost all entries are consecutively 1s or 0s, this method is slower and takes more memory space than a sparse implementation</li>
<li>Benefits:<ul>
<li>Enables native bitwise ops (AND/OR/XOR/NOT), popcount, shifts, etc.</li>
<li>SIMD, simpler/faster multithreading on most operations</li>
</ul>
</li>
</ul>
<p><b>Binary list</b></p><ul>
<li>Example: <code>ex = [0,1,1,0,0,1,1,1]</code></li>
<li>Drawback: each element takes up a whole byte while only one bit is needed. Poor memory density and difficult SIMD exploitation makes this approach slow in almost any scenario.</li>
</ul>
<p><b>Sparse intervals</b></p><ul>
<li>Example: <code>ex = [(1,3),(5,8)]</code> denotes runs of consecutive 1s. <br  />
</li>
<li>Drawback: good for very very sparse patterns but degrades rapidely to O(n). Enormous overhead for most cases.</li>
</ul>
<p><img src="https://github.com/algolab-quantique/Stage-A25-Zakary/blob/main/assets/datastruct_comparison.png" alt="" align="center" width="300" class="inline"/></p>
<p>&mdash; --&gt; </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
